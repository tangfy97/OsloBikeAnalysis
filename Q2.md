# Q2

### 1. How would you retrieve the data that is updated daily and incorporate it into your dataset? 

##### Simple solution (without 3rd party API)
Since the data so far is not massive and works under the simple pymysql module, we can use the follow steps to update the daily data:

+ Use the get method of the ``Requests`` module to download the latest dataset from this **[URL](https://oslobysykkel.no/en/open-data/historical)**
+ Process Norwegian characters (åøæ) through `convert_norsk_char.py`, use `load_one_csv.py` to load them into the mySQL database

##### With 3rd party API
To retrieve the data that is updated daily and incorporate it into the dataset, one approach could be to use a scheduler tool such as Apache Airflow or cron to schedule a daily data extraction script that uses the MySQL connector for python to query the Oslo City Bike API and retrieve the data. 
The script can then insert the new data into the recent data table in the MySQL database using standard SQL insert statements.

#### 1.1 How would you schedule it?
Scheduling can be done by setting up a daily task to run at a specific time using Apache Airflow or cron. 
For example, the task can be set to run every day at midnight to extract data for the previous day. This ensures that the dataset is always up to date with the latest data from the API.

### 2. Imagine that you have to maintain a list of the most common start-end station pairs:

#### 2.1 How would you design the data model

##### Simple solution:

Since the new data coming in every day is NOT huge, we can design two tables, one for historical data and one for recent, both in the format `start_station | end_station | count`.
Corresponds to *Q2.2*, however, this approach requires to add updated daily data into the recent table, and also decide a timeframe to retire the current one and move it into the historical one.

##### Sustainable solution:

To maintain a list of the most common start-end station pairs, one approach could be to use a denormalized data model where the start and end station pairs are stored in a separate table with a count column that keeps track of the number of times each pair has been used.
The table could also include the date range for which the count is valid, so that it can be updated as new data comes in.


#### 2.2 How would you keep it up to date as new data comes in

To keep the list up to date as new data comes in, a scheduled task could be set up to run periodically (e.g. daily or weekly) that updates the count of each start-end station pair based on the new data. For example, the task could run a SQL query that joins the trip data table with the start-end station pairs table, groups the data by start and end stations, and updates the count column with the new counts.


### 3. Assume there is an update to the bike infrastructure in Oslo some months in the future and some of the existing bike stations are removed. How would you modify your model to take into account historical stations that are no longer used

To modify the model to take into account historical stations that are no longer used, one approach could be to add a column to the station table indicating whether a station is active or inactive. For example, if a station is removed from the bike infrastructure, the corresponding row in the station table could be updated to set the active column to **FALSE**.
When extracting the data from the API, only the active stations should be considered. If a station is inactive, the data for the station should not be recorded in the database. When querying the data, only the active stations should be considered. If a station is inactive, the data for the station should not be included in the result.
Additionally, we can keep an historical seperate copy of the data for the removed stations, so it can be used for further analysis. For instance, to see the historical data of the station's usage in the past.
